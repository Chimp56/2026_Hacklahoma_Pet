Metadata-Version: 2.4
Name: pet-api
Version: 0.1.0
Summary: Pet API - FastAPI backend
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: fastapi
Requires-Dist: uvicorn[standard]>=0.27.0
Requires-Dist: pydantic>=2.5.0
Requires-Dist: pydantic-settings>=2.1.0
Requires-Dist: sqlalchemy[asyncio]>=2.0.25
Requires-Dist: asyncpg>=0.29.0
Requires-Dist: httpx>=0.26.0
Requires-Dist: google-genai
Requires-Dist: pillow>=10.0.0
Requires-Dist: google>=3.0.0
Requires-Dist: python-multipart>=0.0.22
Requires-Dist: boto3>=1.34.0
Requires-Dist: alembic>=1.13.0
Requires-Dist: transformers>=4.45.0
Requires-Dist: torch>=2.0.0
Requires-Dist: accelerate>=0.33.0
Provides-Extra: dev
Requires-Dist: pytest>=7.4.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.23.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"

# Pet API (FastAPI)

FastAPI backend with async SQLAlchemy, Pydantic v2, and versioned API.

## Setup

Install uv: https://docs.astral.sh/uv/getting-started/installation/

```bash
cd backend
uv venv
# .venv/Scripts/activate   # Windows
source .venv/bin/activate  # macOS/Linux
uv sync
cp .env.example .env     # Edit .env with your DATABASE_URL and SECRET_KEY
```

## Run

```bash
uv run run.py
# or: uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

- API: http://localhost:8000  
- Docs: http://localhost:8000/docs  
- Health: http://localhost:8000/health  

## Migrations (Alembic)

Uses `DATABASE_URL` from `.env` (PostgreSQL with asyncpg).

```bash
cd backend
alembic revision --autogenerate -m "describe your change"
alembic upgrade head
# Rollback one revision:
alembic downgrade -1
```

## Tests

```bash
pytest
```

## AI models (image / audio)

- **Gemini** – image and audio analysis. Set `GEMINI_API_KEY` in `.env`.
- **Llama 3.2 1B Instruct** – text-only. Use `LLAMA_BACKEND=transformers` (local pipeline, needs `transformers`/`torch`) or `LLAMA_BACKEND=inference_api` (HF API; set `HF_TOKEN`). For image/audio use `model=gemini` or `model=llama_vision`.

Use `POST /api/v1/gemini/analyze-pet?model=gemini` for images. Audio is supported only with `model=gemini`. Llama is available for text generation (no image/audio).

## File storage

- **Local** – `STORAGE_BACKEND=local`, files under `STORAGE_LOCAL_PATH` (default `./storage`).
- **DigitalOcean Spaces** – set `STORAGE_BACKEND=digitalocean` and DO credentials (`DO_SPACES_*`). Same keys work for migration.

`POST /api/v1/media/upload` uploads images, audio, or video.

## Notifications (Slack)

- Set `SLACK_WEBHOOK_URL` (incoming webhook). Optionally `NOTIFICATION_FLAG_EVENTS=milestone,health_alert,anomaly`.
- When a detection is **flagged** (event type in the list), the app can send to Slack. Use `POST /api/v1/notifications/notify-event` to trigger or test.

## Project layout

```
app/
├── main.py              # App factory, CORS, lifespan
├── config.py            # Pydantic Settings from env
├── api/v1/
│   ├── router.py        # Aggregates v1 endpoints
│   └── endpoints/       # pets, gemini (AI), media, notifications
├── core/                # Dependencies, security
├── db/                  # Async engine, session, Base
├── models/              # User, Pet, Activity, Milestone, LLMOutput, CommunityPost, MediaFile
├── schemas/             # Pydantic request/response
├── crud/                # CRUD operations per model
└── services/
    ├── storage/        # File storage (local + DigitalOcean Spaces)
    ├── ai/             # AI providers (Gemini, Llama registry)
    └── notifications/  # Flag algorithm + Slack
alembic/                # Migrations (env.py uses app config + models)
tests/
```
